{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import lda\n",
    "from sklearn.externals import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['class_id', 'title', 'description']\n",
    "train_df = pd.read_csv('../data/ag_news/train.csv', header=None, names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.title = train_df.title.str.lower()\n",
    "train_df.description = train_df.description.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.title.values + ' ' + train_df.description.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_model = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow = bow_model.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_model.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(bow_model, '../models/bow_model.pkl')\n",
    "bow_model = joblib.load('../models/bow_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bow_model.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = [20, 100, 200]\n",
    "n_iter = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ag_news_iter2000_done_time.txt', 'w') as f:\n",
    "    for n in n_topics:\n",
    "        start = time.time()\n",
    "        lda_model = lda.lda.LDA(n_topics=n, n_iter=n_iter, random_state=0)\n",
    "        lda_model.fit(bow)\n",
    "        joblib.dump(lda_model, '../models/lda_model_{}_{}iter.pkl'.format(n, n_iter))\n",
    "        end = time.time()\n",
    "        print(\"topic_N =\", str(n), \"train time\", end - start, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_100 = joblib.load('../models/lda_model_100_2000iter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = bow_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in lda_model_100.components_:\n",
    "    sorted_index = np.argsort(topic)[::-1]\n",
    "    top_words = np.array([feature_names[i] for i in sorted_index[:20]])\n",
    "    print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bow_model.transform(train_x)\n",
    "theta_docs_100 = lda_model_100.transform(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_100_df = pd.DataFrame(theta_docs_100)\n",
    "\n",
    "topic_100_df.columns = ['topic' + str(i) for i in range(100)]\n",
    "\n",
    "pd.concat([train_df, topic_100_df], axis=1).to_csv('../data/ag_news/topic100_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/ag_news/test.csv', header=None, names=header)\n",
    "\n",
    "test_df.title = test_df.title.str.lower()\n",
    "test_df.description = test_df.description.str.lower()\n",
    "\n",
    "test_x = test_df.title.values + ' ' + test_df.description.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bow_model.transform(test_x)\n",
    "theta_docs_100 = lda_model_100.transform(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_100_df = pd.DataFrame(theta_docs_100)\n",
    "\n",
    "topic_100_df.columns = ['topic' + str(i) for i in range(100)]\n",
    "\n",
    "pd.concat([test_df, topic_100_df], axis=1).to_csv('../data/ag_news/topic100_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_20 = joblib.load('../models/lda_model_20_2000iter.pkl')\n",
    "\n",
    "feature_names = bow_model.get_feature_names()\n",
    "\n",
    "for topic in lda_model_20.components_:\n",
    "    sorted_index = np.argsort(topic)[::-1]\n",
    "    top_words = np.array([feature_names[i] for i in sorted_index[:20]])\n",
    "    print(top_words)\n",
    "    \n",
    "bow = bow_model.transform(train_x)\n",
    "theta_docs_20 = lda_model_20.transform(bow)\n",
    "\n",
    "topic_20_df = pd.DataFrame(theta_docs_20)\n",
    "\n",
    "topic_20_df.columns = ['topic' + str(i) for i in range(20)]\n",
    "\n",
    "pd.concat([train_df, topic_20_df], axis=1).to_csv('../data/ag_news/topic20_train.csv', index=False)\n",
    "\n",
    "bow = bow_model.transform(test_x)\n",
    "theta_docs_20 = lda_model_20.transform(bow)\n",
    "\n",
    "topic_20_df = pd.DataFrame(theta_docs_20)\n",
    "\n",
    "topic_20_df.columns = ['topic' + str(i) for i in range(20)]\n",
    "\n",
    "pd.concat([test_df, topic_20_df], axis=1).to_csv('../data/ag_news/topic20_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_200 = joblib.load('../models/lda_model_200_2000iter.pkl')\n",
    "\n",
    "feature_names = bow_model.get_feature_names()\n",
    "\n",
    "for topic in lda_model_200.components_:\n",
    "    sorted_index = np.argsort(topic)[::-1]\n",
    "    top_words = np.array([feature_names[i] for i in sorted_index[:20]])\n",
    "    print(top_words)\n",
    "    \n",
    "bow = bow_model.transform(train_x)\n",
    "theta_docs_200 = lda_model_200.transform(bow)\n",
    "\n",
    "topic_200_df = pd.DataFrame(theta_docs_200)\n",
    "\n",
    "topic_200_df.columns = ['topic' + str(i) for i in range(200)]\n",
    "\n",
    "pd.concat([train_df, topic_200_df], axis=1).to_csv('../data/ag_news/topic200_train.csv', index=False)\n",
    "\n",
    "bow = bow_model.transform(test_x)\n",
    "theta_docs_200 = lda_model_200.transform(bow)\n",
    "\n",
    "topic_200_df = pd.DataFrame(theta_docs_200)\n",
    "\n",
    "topic_200_df.columns = ['topic' + str(i) for i in range(200)]\n",
    "\n",
    "pd.concat([test_df, topic_200_df], axis=1).to_csv('../data/ag_news/topic200_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic-transfer",
   "language": "python",
   "name": "topic-transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
